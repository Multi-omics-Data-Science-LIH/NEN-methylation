{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dea411a-1fee-480c-85f3-9b74b1706910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score,cross_val_predict\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 20})\n",
    "import pickle\n",
    "import platform\n",
    "import time\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from numpy import interp\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72544062-4e29-477b-8c21-03991cf862ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(csv_file, nrows=None):\n",
    "    df = pd.read_csv(csv_file, nrows=nrows)\n",
    "    print(\"File = {}\".format(csv_file))\n",
    "    print(\"Shape = {:,} rows, {:,} columns\".format(df.shape[0], df.shape[1]))\n",
    "    print(\"Memory usage = {:.2f}GB\".format(df.memory_usage().sum() / 1024**3))\n",
    "    return df\n",
    "\n",
    "data_dir = \".../data/\"\n",
    "\n",
    "df = read_csv(data_dir + \"NEN_ml_xgboosting_update2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc3cbdd-e0e2-4515-8057-6b96f79f71f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = df.iloc[:,list(range(2, len(df.columns),1))]\n",
    "\n",
    "fdf = fdf.drop(labels = ['Age.at.diagnosis', \"Sentrix_ID_new\", 'Ki67', 'index','Localization','Primary','G.phase', 'Gender'],axis = 1)\n",
    "fdf_cup = fdf.loc[fdf['P_grouping'] == \"NEN liver CUP\",:]\n",
    "fdf_cup = fdf_cup.drop(fdf_cup[fdf_cup['ID'] == 240230].index)\n",
    "fdf_meta = fdf.loc[fdf['P_grouping'] == \"NEN liver metastasis\",:]\n",
    "fdf_model = fdf.drop(fdf[(fdf['P_grouping'] == \"NEN liver metastasis\") | (fdf['P_grouping'] == \"NEN liver CUP\" )].index)\n",
    "list_data = [fdf_cup, fdf_meta, fdf_model]\n",
    "# Label the class\n",
    "for i,dataset in enumerate(list_data):\n",
    "    le = LabelEncoder()\n",
    "    le_count = 0\n",
    "    ref_encoding = []\n",
    "\n",
    "    # iterate through columns\n",
    "    for col in dataset:\n",
    "        if dataset.loc[:, col].dtype == 'object':\n",
    "\n",
    "            if len(list(dataset.loc[:, col].unique())) <= 20:\n",
    "  \n",
    "                le.fit(dataset.loc[:, col])\n",
    "                dataset.loc[:, col] = le.transform(dataset.loc[:, col])\n",
    " \n",
    "                # Keep track of how many columns were labeled\n",
    "                le_count += 1\n",
    "                ref_encoding.append(le.classes_)\n",
    "\n",
    "    print('%d columns were label encoded.' % le_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3037a7-25c5-459d-b36c-31c095ed5071",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf_model['P_grouping'].value_counts()\n",
    "fdf_model['P_grouping'].head(4)\n",
    "\n",
    "fdf_model['P_grouping'].plot.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c12f897-7ad4-4285-9795-a2ef8d826d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% model setting\n",
    "\n",
    "y = fdf_model.P_grouping\n",
    "df_pg = fdf_model.drop(['ID','NEN.type','P_grouping'],axis = 1)     #### Keep only the predictive features\n",
    "X = df_pg.copy()\n",
    "\n",
    "print(\"Shape of input data: {} and shape of target variable: {}\".format(X.shape, y.shape))\n",
    "pd.concat([X, y], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2705bb55-8508-4f3f-94ca-12d1f322085a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pg = fdf_meta.drop(['ID','NEN.type','P_grouping'],axis = 1)\n",
    "y_test = fdf_meta.P_grouping   \n",
    "X_test = df_pg.copy()\n",
    "\n",
    "df_pg_cup = fdf_cup.drop(['ID','NEN.type','P_grouping'],axis = 1)\n",
    "X_test_cup = df_pg_cup.copy()\n",
    "\n",
    "\n",
    "print(\"Shape of input data: {} and shape of target variable: {}\".format(X_test.shape, y_test.shape))\n",
    "pd.concat([X_test, y_test], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31372ef0-883e-4d28-a759-95f0baddb531",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.to_numeric(y)\n",
    "\n",
    "kf = StratifiedKFold(n_splits=3)\n",
    "counter_kf = 1\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    print(f'Fold:{counter_kf}, Train set: {len(train_index)}, Test set:{len(test_index)}')\n",
    "    counter_kf+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0389f27c-5de4-4e7d-8ac2-45558c2a3204",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cross_val_score(RandomForestClassifier(n_estimators=2000, random_state = 3,max_features=\"sqrt\",\n",
    "                                               criterion=\"gini\", oob_score=True,\n",
    "                                                n_jobs=10, max_depth=12),\n",
    "                                               X, y, cv= kf, scoring=\"accuracy\")\n",
    "print(f'Scores for each fold are: {score}')\n",
    "print(f'Average score: {\"{:.2f}\".format(score.mean())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1eabc7-b143-4aee-8c31-fc780278e8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the CV score\n",
    "y_pred = cross_val_predict(RandomForestClassifier(n_estimators=2000, random_state = 3,max_features=\"sqrt\",\n",
    "                                               criterion=\"gini\", oob_score=True,\n",
    "                                                n_jobs=10, max_depth=12),\n",
    "                                               X, y, cv= kf)\n",
    "conf_mat = confusion_matrix(y,y_pred)\n",
    "\n",
    "confusion_matrix_cv = pd.DataFrame(conf_mat, columns = ref_encoding[1], index = ref_encoding[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41eccf8-bc9b-40b4-909f-a191a0002c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6e68ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_cv.to_csv('.../data/test_output/confusion_matrix2_xgboosting.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d01ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, roc_auc_score, classification_report\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# Define the output directory\n",
    "output_dir = \".../data/test_output/\"\n",
    "\n",
    "# Model prediction using cross-validation\n",
    "y_pred = cross_val_predict(\n",
    "    RandomForestClassifier(\n",
    "        n_estimators=2000, random_state=3, max_features=\"sqrt\",\n",
    "        criterion=\"gini\", oob_score=True, n_jobs=10, max_depth=12\n",
    "    ),\n",
    "    X, y, cv=kf\n",
    ")\n",
    "\n",
    "# Compute evaluation metrics\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "precision = precision_score(y, y_pred, average=\"weighted\")\n",
    "recall = recall_score(y, y_pred, average=\"weighted\")\n",
    "f1 = f1_score(y, y_pred, average=\"weighted\")\n",
    "\n",
    "# Attempt to calculate AUC-ROC score\n",
    "try:\n",
    "    auc = roc_auc_score(pd.get_dummies(y), pd.get_dummies(y_pred), average=\"weighted\", multi_class=\"ovr\")\n",
    "except ValueError:\n",
    "    auc = None\n",
    "\n",
    "# Save metrics to CSV\n",
    "metrics = {\n",
    "    \"Metric\": [\"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"AUC-ROC\"],\n",
    "    \"Score\": [accuracy, precision, recall, f1, auc]\n",
    "}\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "metrics_df.to_csv(f\"{output_dir}model_metrics.csv\", index=False)\n",
    "\n",
    "# Compute and save confusion matrix\n",
    "conf_mat = confusion_matrix(y, y_pred)\n",
    "confusion_matrix_df = pd.DataFrame(conf_mat, index=ref_encoding[1], columns=ref_encoding[1])\n",
    "confusion_matrix_df.to_csv(f\"{output_dir}confusion_matrix.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a8c844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "plt.figure(figsize=(12, 10))  # Increase figure size for clarity\n",
    "\n",
    "sns.set(font_scale=1.5)  # Increase font size\n",
    "sns.heatmap(confusion_matrix_df, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            cbar_kws={'label': 'Number of Samples'}, \n",
    "            xticklabels=confusion_matrix_df.columns,\n",
    "            yticklabels=confusion_matrix_df.index,\n",
    "            linewidths=0.5, linecolor='black')\n",
    "\n",
    "plt.title(\"Confusion Matrix\", fontsize=18)\n",
    "plt.ylabel(\"Actual\", fontsize=16)\n",
    "plt.xlabel(\"Predicted\", fontsize=16)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=14)\n",
    "plt.yticks(rotation=0, fontsize=14)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save high-resolution figure\n",
    "#plt.savefig(\".../data/test_output/confusion_matrix_publication.png\", dpi=300)\n",
    "#plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1690b449-fe95-4244-bc25-deac2d5d6154",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%#%% RF model\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=1500, random_state=3, max_features=\"sqrt\",\n",
    "                                       criterion=\"gini\", oob_score=True, n_jobs=10, max_depth=12,\n",
    "                                       verbose=0)\n",
    "\n",
    "random_forest.fit(X, y)\n",
    "print(random_forest.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf19daec-fb83-491d-9422-26a2cf81b784",
   "metadata": {},
   "outputs": [],
   "source": [
    "testp = random_forest.predict(X_test)\n",
    "testproba = random_forest.predict_proba(X_test)\n",
    "\n",
    "testproba_columns = ref_encoding[1].tolist()\n",
    "testproba= pd.DataFrame(testproba,columns = testproba_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d22d64-c773-40e5-8943-4e1aa573d47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map it back to the origin meta matrix anno\n",
    "\n",
    "testprrediction =[ref_encoding[1][i] for i in testp]\n",
    "testproba_df = pd.DataFrame(testproba)\n",
    "\n",
    "fdf_1 = df.iloc[:,list(range(2, len(df.columns),1))]\n",
    "fdf_meta_result = fdf_1.loc[fdf_1['P_grouping'] == \"NEN liver metastasis\",:]\n",
    "fdf_meta_result['prediction'] = testprrediction\n",
    "fdf_comp = fdf_meta_result.loc[:, ('ID','prediction','Primary')]\n",
    "\n",
    "fdf_comp.reset_index(drop=True, inplace=True)\n",
    "testproba_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "fdf_comp_met = pd.concat([fdf_comp,testproba_df], axis=1, ignore_index=True)\n",
    "fdf_comp_met.columns = ['ID','prediction','Primary']+testproba_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6294b8-6355-4121-9324-f77adfc05de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf_comp_met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c33bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions and probabilities\n",
    "test_predictions = random_forest.predict(X_test)\n",
    "test_probabilities = random_forest.predict_proba(X_test)\n",
    "\n",
    "# Convert probabilities to DataFrame with proper column names\n",
    "testproba_columns = ref_encoding[1].tolist()\n",
    "test_probabilities_df = pd.DataFrame(test_probabilities, columns=testproba_columns)\n",
    "\n",
    "# Map predicted indices back to original class labels\n",
    "test_prediction_labels = [ref_encoding[1][i] for i in test_predictions]\n",
    "\n",
    "# Extract relevant metadata from df\n",
    "fdf_1 = df.iloc[:, list(range(2, len(df.columns), 1))]\n",
    "fdf_meta_result = fdf_1[fdf_1['P_grouping'] == \"NEN liver metastasis\"].copy()\n",
    "\n",
    "# Add prediction column\n",
    "fdf_meta_result['prediction'] = test_prediction_labels\n",
    "\n",
    "# Select specific columns\n",
    "fdf_comp = fdf_meta_result.loc[:, ['ID', 'prediction', 'Primary']]\n",
    "\n",
    "# Reset indexes\n",
    "fdf_comp.reset_index(drop=True, inplace=True)\n",
    "test_probabilities_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Concatenate predictions with probabilities\n",
    "fdf_comp_met = pd.concat([fdf_comp, test_probabilities_df], axis=1)\n",
    "\n",
    "# Define clean columns\n",
    "fdf_comp_met.columns = ['ID', 'Prediction', 'Primary'] + testproba_columns\n",
    "\n",
    "# Save as CSV for publication (clean table)\n",
    "output_path = \".../data/test_output/NEN_metastasis_predictions.csv\"\n",
    "#fdf_comp_met.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Publication-ready table saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72339eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "# Define output path\n",
    "output_dir = \".../data/test_output/\"\n",
    "\n",
    "# Mapping for ground truth\n",
    "mapping = {\n",
    "    \"Pancreas\": \"NEN pancreas\",\n",
    "    \"Ileum\": \"NEN ileum\",\n",
    "    \"Colon\": \"NEN colorectal\",\n",
    "    \"Duodenum\": \"NEN gastroduodenal\",\n",
    "    \"SCLC\": \"Pulmonal NEC\"\n",
    "}\n",
    "\n",
    "\n",
    "true_labels = fdf_comp_met[\"Primary\"].replace(mapping)\n",
    "\n",
    "# Predicted labels\n",
    "pred_labels = fdf_comp_met[\"Prediction\"]  # Note: we used 'Prediction' as column name in previous step\n",
    "\n",
    "# Get unique sorted labels\n",
    "labels = sorted(list(set(true_labels.unique()).union(set(pred_labels.unique()))))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(true_labels, pred_labels, labels=labels)\n",
    "\n",
    "# Convert to DataFrame for display and export\n",
    "cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "\n",
    "# Save confusion matrix as CSV for paper\n",
    "cm_df.to_csv(f\"{output_dir}confusion_matrix_liver_metastasis.csv\")\n",
    "\n",
    "# Plot: publication quality\n",
    "plt.figure(figsize=(12, 10))  # Increased size for clarity\n",
    "sns.set(font_scale=1.5)  # Increase font size\n",
    "sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues',\n",
    "            cbar_kws={'label': 'Number of Samples'},\n",
    "            xticklabels=labels, yticklabels=labels,\n",
    "            linewidths=0.5, linecolor='black')\n",
    "\n",
    "plt.title(\"Confusion Matrix for Liver Metastasis Predictions\", fontsize=18)\n",
    "plt.xlabel(\"Predicted Labels\", fontsize=16)\n",
    "plt.ylabel(\"True Labels\", fontsize=16)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=14)\n",
    "plt.yticks(rotation=0, fontsize=14)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save high-resolution figure\n",
    "#plt.savefig(f\"{output_dir}confusion_matrix_liver_metastasis.png\", dpi=300)\n",
    "#plt.close()\n",
    "\n",
    "print(f\"Confusion matrix saved to: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a8960d",
   "metadata": {},
   "outputs": [],
   "source": [
    "testp_cup = random_forest.predict(X_test_cup)\n",
    "testproba_cup = random_forest.predict_proba(X_test_cup)\n",
    "\n",
    "testproba_columns = ref_encoding[1].tolist()\n",
    "testproba_cup= pd.DataFrame(testproba_cup,columns = testproba_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fc0983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map it back to the origin meta matrix anno\n",
    "\n",
    "testprrediction_cup =[ref_encoding[1][i] for i in testp_cup]\n",
    "testproba_cup_df = pd.DataFrame(testproba_cup)\n",
    "\n",
    "fdf_1 = df.iloc[:,list(range(2, len(df.columns),1))]\n",
    "fdf_cup_result = fdf_1.loc[fdf_1['P_grouping'] == \"NEN liver CUP\",:]\n",
    "fdf_cup_result = fdf_cup_result.drop(fdf_cup_result[fdf_cup_result['ID'] == 240230].index)\n",
    "fdf_cup_result['prediction'] = testprrediction_cup\n",
    "fdf_comp_cup = fdf_cup_result.loc[:, ('ID','prediction','Primary')]\n",
    "\n",
    "fdf_comp_cup.reset_index(drop=True, inplace=True)\n",
    "testproba_cup_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "fdf_comp_cup2 = pd.concat([fdf_comp_cup,testproba_cup_df], axis=1, ignore_index=True)\n",
    "fdf_comp_cup2.columns = ['ID','prediction','Primary']+testproba_columns\n",
    "fdf_comp_cup2.to_csv(data_dir +'res_cup_predictions probability.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f08c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf_comp_cup2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8554f2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% feature importance\n",
    "\n",
    "feature_importance_values = random_forest.feature_importances_\n",
    "feature_importances = pd.DataFrame({'feature': X.columns, 'importance': feature_importance_values})\n",
    "# feature_importances.to_csv(os.getcwd() + '/featureimp_res_5k.txt', sep='\\t')\n",
    "#%%\n",
    "# %% CV_AUC\n",
    "X = X.values\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b798b764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "P_group = ref_encoding[1]\n",
    "conl = list()\n",
    "indexl = list()\n",
    "for i in P_group:\n",
    "    conl.append(i)\n",
    "    index = np.where(ref_encoding[1] == i)[0]\n",
    "    indexl.append(index[0])\n",
    "\n",
    "for idx, item in zip(indexl, conl):\n",
    "    print(idx, item)\n",
    "    classifier = random_forest\n",
    "\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    plt.figure(figsize=(14, 9))\n",
    "    i = 0\n",
    "    for train, test in kf.split(X, y):\n",
    "        probas_ = classifier.fit(X[train], y[train]).predict_proba(X[test])\n",
    "        fpr, tpr, thresholds = roc_curve(y[test], probas_[:, idx], pos_label=idx)\n",
    "        tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)  # Ensure auc is not redefined elsewhere\n",
    "        aucs.append(roc_auc)\n",
    "        plt.plot(fpr, tpr, lw=1, alpha=0.3,\n",
    "                 label=f'ROC fold {i} (AUC = {roc_auc:.2f})')\n",
    "        i += 1\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "             label='Chance', alpha=.8)\n",
    "\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "             label=f'Mean ROC (AUC = {mean_auc:.2f} ± {std_auc:.2f})',\n",
    "             lw=2, alpha=.8)\n",
    "\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                     label=r'± 1 std. dev.')\n",
    "\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'{item}_Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    #plt.savefig(f'{data_dir}training/{item}_ROC_AUC_3CV.svg', format=\"svg\")\n",
    "    #plt.savefig(f'{data_dir}training/{item}_ROC_AUC_3CV.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a00b739",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# 1) get the predictions again\n",
    "y_pred = cross_val_predict(\n",
    "    RandomForestClassifier(\n",
    "        n_estimators=2000,\n",
    "        random_state=3,\n",
    "        max_features=\"sqrt\",\n",
    "        criterion=\"gini\",\n",
    "        oob_score=True,\n",
    "        n_jobs=10,\n",
    "        max_depth=12\n",
    "    ),\n",
    "    X, y, cv=kf\n",
    ")\n",
    "\n",
    "# 2) pull out the IDs from fdf_model\n",
    "ids = fdf_model['ID'].values\n",
    "\n",
    "# 3) build a small results DataFrame\n",
    "results = pd.DataFrame({\n",
    "    'ID':        ids,\n",
    "    'True':      y,\n",
    "    'Predicted': y_pred\n",
    "})\n",
    "\n",
    "# 4) filter to the misclassified\n",
    "mis = results[results['True'] != results['Predicted']]\n",
    "\n",
    "# 5) merge in the 'Primary' label from your original df\n",
    "mis = mis.merge(df[['ID','Primary']], on='ID', how='left')\n",
    "\n",
    "# 6) show just the three columns you asked for\n",
    "print(f\"Found {len(mis)} misclassified samples:\\n\")\n",
    "\n",
    "target_labels = list(ref_encoding[1])\n",
    "\n",
    "# 2) build a mapping from code → label\n",
    "label_map = { i: lbl for i, lbl in enumerate(target_labels) }\n",
    "\n",
    "# 3) overwrite the numeric codes in 'Predicted' with the string names\n",
    "mis['Predicted'] = mis['Predicted'].map(label_map)\n",
    "\n",
    "# 4) show just the three columns you asked for\n",
    "print(mis[['ID','Primary','Predicted']])\n",
    "\n",
    "# (optional) save to CSV\n",
    "mis[['ID','Primary','Predicted']].to_csv(\n",
    "    '.../data/RF_results/xg_boosting_misclassified_table.csv',\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9e7598-4571-4711-b034-fdc9a937054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_data = read_csv(data_dir + \"NEN_ml_xgb_val_update.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aead530f-3d24-46ed-98bc-c31cbe7f740f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f3bf34-030b-49aa-8d07-67f15f177ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(unseen_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbd24a5-2862-4bf9-8f0f-1e9996a78ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Prepare the features for prediction \n",
    "# In training, you dropped ['ID', 'NEN.type', 'P_grouping'] to form X.\n",
    "#X_test_new = unseen_data.drop(['ID', 'NEN.type', 'P_grouping', 'Localization', 'Primary', 'index'], axis=1)\n",
    "X_test_new = unseen_data.drop(['ID', 'NEN.type', 'P_grouping', 'Localization', 'Primary'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0eb39f-06f0-4e00-8116-56e2c3c4aff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc772d57-0e18-4111-8a9d-e5e08834eb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  3. Use the trained model to make predictions\n",
    "# Predict the class labels (as numbers) and the class probabilities\n",
    "preds_numeric = random_forest.predict(X_test_new)\n",
    "preds_proba = random_forest.predict_proba(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2c36ea-d1ca-4ed3-9d6b-33f3dc790eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Convert numeric predictions back to original class names \n",
    "# Here we assume that ref_encoding[3] holds the original classes (e.g., ['NEN liver metastasis', 'NEN liver CUP', ...])\n",
    "target_labels = ref_encoding[1].tolist()  # adjust the index if needed\n",
    "predicted_labels = [target_labels[i] for i in preds_numeric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0c46f0-49de-4200-8575-cd7bf54af1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Build the final results DataFrame \n",
    "# Create a DataFrame for the probabilities with appropriate column names\n",
    "preds_proba_df = pd.DataFrame(preds_proba, columns=target_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c335ea-a836-410f-ac67-a14946fbfb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_proba_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dfd108-4fc4-4311-a8a8-8929bb38aba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = unseen_data[['ID', 'Primary']].copy()\n",
    "results_df['prediction'] = predicted_labels\n",
    "# Reorder columns to match your desired output: ['ID','prediction','Primary']\n",
    "results_df = results_df[['ID', 'prediction', 'Primary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02f2c22-ac94-4dd6-a072-846dbf646ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index and concatenate with the probability DataFrame\n",
    "results_df.reset_index(drop=True, inplace=True)\n",
    "preds_proba_df.reset_index(drop=True, inplace=True)\n",
    "final_results = pd.concat([results_df, preds_proba_df], axis=1)\n",
    "# Optionally, rename the probability columns (here they are already set via target_labels)\n",
    "final_results.columns = ['ID', 'prediction', 'Primary'] + target_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970a44df-dc9b-4321-ba27-73836b81ff03",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9356f8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results.to_csv('.../data/test_output/validation_xgb.csv', sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "nt_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
