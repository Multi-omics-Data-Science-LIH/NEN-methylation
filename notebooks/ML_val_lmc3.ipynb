{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1734c3c8-39fc-4b46-963e-2aa89df3bd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score,cross_val_predict\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 20})\n",
    "import pickle\n",
    "import platform\n",
    "import time\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from numpy import interp\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7c1872-7cca-46c1-b0e4-9f68659b2e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(csv_file, nrows=None):\n",
    "    df = pd.read_csv(csv_file, nrows=nrows)\n",
    "    print(\"File = {}\".format(csv_file))\n",
    "    print(\"Shape = {:,} rows, {:,} columns\".format(df.shape[0], df.shape[1]))\n",
    "    print(\"Memory usage = {:.2f}GB\".format(df.memory_usage().sum() / 1024**3))\n",
    "    return df\n",
    "\n",
    "data_dir = \".../data/\"\n",
    "\n",
    "df = read_csv(data_dir + \"NEN_ml_5k_res_test_update.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50847656-6b68-4ec8-9972-68c6420a36c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = df.iloc[:,list(range(2, len(df.columns),1))]\n",
    "\n",
    "fdf = fdf.drop(labels = ['Age.at.diagnosis', \"Sentrix_ID_new\", 'Ki67', 'index','Localization','Primary','G.phase', 'Gender'],axis = 1)\n",
    "fdf_cup = fdf.loc[fdf['P_grouping'] == \"NEN liver CUP\",:]\n",
    "fdf_cup = fdf_cup.drop(fdf_cup[fdf_cup['ID'] == 240230].index)\n",
    "fdf_meta = fdf.loc[fdf['P_grouping'] == \"NEN liver metastasis\",:]\n",
    "fdf_model = fdf.drop(fdf[(fdf['P_grouping'] == \"NEN liver metastasis\") | (fdf['P_grouping'] == \"NEN liver CUP\" )].index)\n",
    "list_data = [fdf_cup, fdf_meta, fdf_model]\n",
    "# Label the class\n",
    "for i,dataset in enumerate(list_data):\n",
    "    le = LabelEncoder()\n",
    "    le_count = 0\n",
    "    ref_encoding = []\n",
    "\n",
    "    # iterate through columns\n",
    "    for col in dataset:\n",
    "        if dataset.loc[:, col].dtype == 'object':\n",
    "            if len(list(dataset.loc[:, col].unique())) <= 20:\n",
    "                le.fit(dataset.loc[:, col])\n",
    "                dataset.loc[:, col] = le.transform(dataset.loc[:, col])\n",
    "                le_count += 1\n",
    "                ref_encoding.append(le.classes_)\n",
    "\n",
    "    print('%d columns were label encoded.' % le_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ffb160-dfff-447f-91e7-4e6791659c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf_model['P_grouping'].value_counts()\n",
    "fdf_model['P_grouping'].head(4)\n",
    "\n",
    "fdf_model['P_grouping'].plot.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1f359f-6eb2-4d73-81b0-afe122ae0744",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% model setting\n",
    "\n",
    "y = fdf_model.P_grouping\n",
    "df_pg = fdf_model.drop(['ID','NEN.type','P_grouping'],axis = 1)     #### Keep only the predictive features\n",
    "X = df_pg.copy()\n",
    "\n",
    "print(\"Shape of input data: {} and shape of target variable: {}\".format(X.shape, y.shape))\n",
    "pd.concat([X, y], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4677dbfa-d0cd-46a9-bf9b-92a3433c0ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pg = fdf_meta.drop(['ID','NEN.type','P_grouping'],axis = 1)\n",
    "y_test = fdf_meta.P_grouping   \n",
    "X_test = df_pg.copy()\n",
    "\n",
    "df_pg_cup = fdf_cup.drop(['ID','NEN.type','P_grouping'],axis = 1)\n",
    "X_test_cup = df_pg_cup.copy()\n",
    "\n",
    "\n",
    "print(\"Shape of input data: {} and shape of target variable: {}\".format(X_test.shape, y_test.shape))\n",
    "pd.concat([X_test, y_test], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212c2119-7405-491a-a143-12f9b5715b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.to_numeric(y)\n",
    "# The folds are made by preserving the percentage of samples for each class.\n",
    "kf = StratifiedKFold(n_splits=3)\n",
    "counter_kf = 1\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    print(f'Fold:{counter_kf}, Train set: {len(train_index)}, Test set:{len(test_index)}')\n",
    "    counter_kf+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b887ee3b-dba0-45bc-b952-db3fd4a49a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cross_val_score(RandomForestClassifier(n_estimators=2000, random_state = 3,max_features=\"sqrt\",\n",
    "                                               criterion=\"gini\", oob_score=True,\n",
    "                                                n_jobs=10, max_depth=12),\n",
    "                                               X, y, cv= kf, scoring=\"accuracy\")\n",
    "print(f'Scores for each fold are: {score}')\n",
    "print(f'Average score: {\"{:.2f}\".format(score.mean())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a62b83a-0da5-48ea-a26b-0675b49bd23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the CV score\n",
    "y_pred = cross_val_predict(RandomForestClassifier(n_estimators=2000, random_state = 3,max_features=\"sqrt\",\n",
    "                                               criterion=\"gini\", oob_score=True,\n",
    "                                                n_jobs=10, max_depth=12),\n",
    "                                               X, y, cv= kf)\n",
    "conf_mat = confusion_matrix(y,y_pred)\n",
    "\n",
    "confusion_matrix_cv = pd.DataFrame(conf_mat, columns = ref_encoding[1], index = ref_encoding[1])\n",
    "#confusion_matrix_cv.to_csv(data_dir + 'RF_results/confusion_matrix2_val.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e521524-7696-4c79-9089-fbf1bb3f8a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%#%% RF model\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=1500, random_state=3, max_features=\"sqrt\",\n",
    "                                       criterion=\"gini\", oob_score=True, n_jobs=10, max_depth=12,\n",
    "                                       verbose=0)\n",
    "\n",
    "random_forest.fit(X, y)\n",
    "print(random_forest.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e24887-51ec-4754-8c5d-37e9992a1c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "testp = random_forest.predict(X_test)\n",
    "testproba = random_forest.predict_proba(X_test)\n",
    "\n",
    "testproba_columns = ref_encoding[1].tolist()\n",
    "testproba= pd.DataFrame(testproba,columns = testproba_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf93e58f-3617-4d89-8a6a-d247352b19c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "testproba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47e7ac9-979c-4651-b054-3342c49fbe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map it back to the origin meta matrix anno\n",
    "\n",
    "testprrediction =[ref_encoding[1][i] for i in testp]\n",
    "testproba_df = pd.DataFrame(testproba)\n",
    "\n",
    "fdf_1 = df.iloc[:,list(range(2, len(df.columns),1))]\n",
    "fdf_meta_result = fdf_1.loc[fdf_1['P_grouping'] == \"NEN liver metastasis\",:]\n",
    "fdf_meta_result['prediction'] = testprrediction\n",
    "fdf_comp = fdf_meta_result.loc[:, ('ID','prediction','Primary')]\n",
    "\n",
    "fdf_comp.reset_index(drop=True, inplace=True)\n",
    "testproba_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "fdf_comp_met = pd.concat([fdf_comp,testproba_df], axis=1, ignore_index=True)\n",
    "fdf_comp_met.columns = ['ID','prediction','Primary']+testproba_columns\n",
    "#testproba.to_csv(data_dir +'res_meta_predictions probability.csv', sep=',')\n",
    "fdf_comp_met.to_csv(data_dir+'RF_results/val_lmc3_results/res_meta_predictions probability.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d099a9a-f276-4482-9fae-dd2b08315c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf_comp_met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95578a90-6999-4155-b3c9-6666123e4063",
   "metadata": {},
   "outputs": [],
   "source": [
    "testp_cup = random_forest.predict(X_test_cup)\n",
    "testproba_cup = random_forest.predict_proba(X_test_cup)\n",
    "\n",
    "testproba_columns = ref_encoding[1].tolist()\n",
    "testproba_cup= pd.DataFrame(testproba_cup,columns = testproba_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e110a0-6bf7-4fd5-9382-374fa18b9202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map it back to the origin meta matrix anno\n",
    "\n",
    "testprrediction_cup =[ref_encoding[1][i] for i in testp_cup]\n",
    "testproba_cup_df = pd.DataFrame(testproba_cup)\n",
    "\n",
    "fdf_1 = df.iloc[:,list(range(2, len(df.columns),1))]\n",
    "fdf_cup_result = fdf_1.loc[fdf_1['P_grouping'] == \"NEN liver CUP\",:]\n",
    "fdf_cup_result = fdf_cup_result.drop(fdf_cup_result[fdf_cup_result['ID'] == 240230].index)\n",
    "fdf_cup_result['prediction'] = testprrediction_cup\n",
    "fdf_comp_cup = fdf_cup_result.loc[:, ('ID','prediction','Primary')]\n",
    "\n",
    "fdf_comp_cup.reset_index(drop=True, inplace=True)\n",
    "testproba_cup_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "fdf_comp_cup2 = pd.concat([fdf_comp_cup,testproba_cup_df], axis=1, ignore_index=True)\n",
    "fdf_comp_cup2.columns = ['ID','prediction','Primary']+testproba_columns\n",
    "fdf_comp_cup2.to_csv(data_dir +'RF_results/val_lmc3_results/res_cup_predictions probability.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b006f41-2c1c-4fe7-a422-00b11d6d3651",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf_comp_cup2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9412d98b-626b-4c81-aced-8ef52f944e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% feature importance\n",
    "\n",
    "feature_importance_values = random_forest.feature_importances_\n",
    "feature_importances = pd.DataFrame({'feature': X.columns, 'importance': feature_importance_values})\n",
    "# feature_importances.to_csv(os.getcwd() + '/featureimp_res_5k.txt', sep='\\t')\n",
    "#%%\n",
    "# %% CV_AUC\n",
    "X = X.values\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbd3a8f-b9e3-46eb-aef8-c0c770d6abda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "P_group = ref_encoding[1]\n",
    "conl = list()\n",
    "indexl = list()\n",
    "for i in P_group:\n",
    "    conl.append(i)\n",
    "    index = np.where(ref_encoding[1] == i)[0]\n",
    "    indexl.append(index[0])\n",
    "\n",
    "for idx, item in zip(indexl, conl):\n",
    "    print(idx, item)\n",
    "    classifier = random_forest\n",
    "\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    plt.figure(figsize=(14, 9))\n",
    "    i = 0\n",
    "    for train, test in kf.split(X, y):\n",
    "        probas_ = classifier.fit(X[train], y[train]).predict_proba(X[test])\n",
    "        fpr, tpr, thresholds = roc_curve(y[test], probas_[:, idx], pos_label=idx)\n",
    "        tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)  # Ensure auc is not redefined elsewhere\n",
    "        aucs.append(roc_auc)\n",
    "        plt.plot(fpr, tpr, lw=1, alpha=0.3,\n",
    "                 label=f'ROC fold {i} (AUC = {roc_auc:.2f})')\n",
    "        i += 1\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "             label='Chance', alpha=.8)\n",
    "\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "             label=f'Mean ROC (AUC = {mean_auc:.2f} ± {std_auc:.2f})',\n",
    "             lw=2, alpha=.8)\n",
    "\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                     label=r'± 1 std. dev.')\n",
    "\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'{item}_Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    #plt.savefig(f'{data_dir}RF_results/val_lmc3_results/{item}_ROC_AUC_3CV.svg', format=\"svg\")\n",
    "    #plt.savefig(f'{data_dir}RF_results/val_lmc3_results/{item}_ROC_AUC_3CV.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b37d86-6722-4dda-9a69-ad1d6caf9eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "# Evaluate model performance with additional metrics\n",
    "# Use cross-validation predictions for evaluation\n",
    "y_pred = cross_val_predict(\n",
    "    RandomForestClassifier(n_estimators=2000, random_state=3, max_features=\"sqrt\",\n",
    "                           criterion=\"gini\", oob_score=True, n_jobs=10, max_depth=12),\n",
    "    X, y, cv=kf\n",
    ")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_mat = confusion_matrix(y, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_mat)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision = precision_score(y, y_pred, average=\"weighted\")  # Use 'macro' or 'micro' as needed\n",
    "recall = recall_score(y, y_pred, average=\"weighted\")\n",
    "f1 = f1_score(y, y_pred, average=\"weighted\")\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1:.2f}\")\n",
    "\n",
    "# AUC-ROC score (if applicable)\n",
    "try:\n",
    "    auc = roc_auc_score(pd.get_dummies(y), pd.get_dummies(y_pred), average=\"weighted\", multi_class=\"ovr\")\n",
    "    print(f\"AUC-ROC Score: {auc:.2f}\")\n",
    "except ValueError as e:\n",
    "    print(\"AUC-ROC Score could not be calculated:\", e)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y, y_pred))\n",
    "\n",
    "# Save metrics to a CSV file\n",
    "metrics = {\n",
    "    \"Metric\": [\"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"AUC-ROC\"],\n",
    "    \"Score\": [accuracy, precision, recall, f1, auc if 'auc' in locals() else None]\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "# metrics_df.to_csv('/mnt/std-pool/homedirs/dtabbakh/nen_project/medcom_2/ML_nen/model_metrics.csv', index=False)\n",
    "\n",
    "# Save confusion matrix\n",
    "confusion_matrix_df = pd.DataFrame(conf_mat, columns=ref_encoding[1], index=ref_encoding[1])\n",
    "# confusion_matrix_df.to_csv('/mnt/std-pool/homedirs/dtabbakh/nen_project/medcom_2/ML_nen/confusion_matrix.csv')\n",
    "\n",
    "# Plot confusion matrix for better visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confusion_matrix_df, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=ref_encoding[1], yticklabels=ref_encoding[1])\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "# plt.savefig('.../data/confusion_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de5e3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- assume you still have ---\n",
    "# df         : your original DataFrame (with the 'ID' and 'Primary' columns)\n",
    "# fdf_model  : the subset you trained on (before dropping ID)\n",
    "# X, y       : your feature matrix & true labels as numpy arrays\n",
    "# kf         : your StratifiedKFold instance\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# 1) get the predictions again\n",
    "y_pred = cross_val_predict(\n",
    "    RandomForestClassifier(\n",
    "        n_estimators=2000,\n",
    "        random_state=3,\n",
    "        max_features=\"sqrt\",\n",
    "        criterion=\"gini\",\n",
    "        oob_score=True,\n",
    "        n_jobs=10,\n",
    "        max_depth=12\n",
    "    ),\n",
    "    X, y, cv=kf\n",
    ")\n",
    "\n",
    "# 2) pull out the IDs from fdf_model\n",
    "ids = fdf_model['ID'].values\n",
    "\n",
    "# 3) build a small results DataFrame\n",
    "results = pd.DataFrame({\n",
    "    'ID':        ids,\n",
    "    'True':      y,\n",
    "    'Predicted': y_pred\n",
    "})\n",
    "\n",
    "# 4) filter to the misclassified\n",
    "mis = results[results['True'] != results['Predicted']]\n",
    "\n",
    "# 5) merge in the 'Primary' label from your original df\n",
    "mis = mis.merge(df[['ID','Primary']], on='ID', how='left')\n",
    "\n",
    "# 6) show just the three columns you asked for\n",
    "print(f\"Found {len(mis)} misclassified samples:\\n\")\n",
    "\n",
    "target_labels = list(ref_encoding[1])\n",
    "\n",
    "# 2) build a mapping from code → label\n",
    "label_map = { i: lbl for i, lbl in enumerate(target_labels) }\n",
    "\n",
    "# 3) overwrite the numeric codes in 'Predicted' with the string names\n",
    "mis['Predicted'] = mis['Predicted'].map(label_map)\n",
    "\n",
    "# 4) show just the three columns you asked for\n",
    "print(mis[['ID','Primary','Predicted']])\n",
    "\n",
    "# (optional) save to CSV\n",
    "mis[['ID','Primary','Predicted']].to_csv(\n",
    "    data_dir + 'RF_results/misclassified_table.csv',\n",
    "    index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a18a7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_data = read_csv(\".../data/test_output/NEN_ml_5k_res_val_update.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ad82c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cfb6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Prepare the features for prediction \n",
    "# In training, you dropped ['ID', 'NEN.type', 'P_grouping'] to form X.\n",
    "X_test_new = unseen_data.drop(['ID', 'NEN.type', 'P_grouping', 'Localization', 'Primary','index'], axis=1)\n",
    "#X_test_new = unseen_data.drop(['ID', 'NEN.type', 'P_grouping', 'Localization', 'Primary'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8008eddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665fee59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Use the trained model to make predictions \n",
    "# Predict the class labels (as numbers) and the class probabilities\n",
    "preds_numeric = random_forest.predict(X_test_new)\n",
    "preds_proba = random_forest.predict_proba(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27aff9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Convert numeric predictions back to original class names \n",
    "# Here we assume that ref_encoding[3] holds the original classes (e.g., ['NEN liver metastasis', 'NEN liver CUP', ...])\n",
    "target_labels = ref_encoding[1].tolist()  # adjust the index if needed\n",
    "predicted_labels = [target_labels[i] for i in preds_numeric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb3a534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Build the final results DataFrame\n",
    "# Create a DataFrame for the probabilities with appropriate column names\n",
    "preds_proba_df = pd.DataFrame(preds_proba, columns=target_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2b5bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_proba_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecce6ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = unseen_data[['ID', 'Primary']].copy()\n",
    "results_df['prediction'] = predicted_labels\n",
    "# Reorder columns to match your desired output: ['ID','prediction','Primary']\n",
    "results_df = results_df[['ID', 'prediction', 'Primary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00afbdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index and concatenate with the probability DataFrame\n",
    "results_df.reset_index(drop=True, inplace=True)\n",
    "preds_proba_df.reset_index(drop=True, inplace=True)\n",
    "final_results = pd.concat([results_df, preds_proba_df], axis=1)\n",
    "# Optionally, rename the probability columns (here they are already set via target_labels)\n",
    "final_results.columns = ['ID', 'prediction', 'Primary'] + target_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03519b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results.to_csv('.../data/test_output/validation_res.csv', sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "nt_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
